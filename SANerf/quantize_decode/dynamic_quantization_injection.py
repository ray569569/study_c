"""
å‹•æ…‹é‡åŒ–æ³¨å…¥æ¨¡çµ„
é€šéç’°å¢ƒè®Šæ•¸å‹•æ…‹æ§åˆ¶é‡åŒ–ç²¾åº¦ï¼Œç„¡éœ€é‡è¤‡ä¿®æ”¹ä»£ç¢¼
"""

import os
import torch
from quantization_plugin import QuantizationPlugin

class DynamicQuantizationManager:
    """å‹•æ…‹é‡åŒ–ç®¡ç†å™¨ - æ ¹æ“šç’°å¢ƒè®Šæ•¸è‡ªå‹•é…ç½®"""
    
    def __init__(self):
        self.quantizer = self._create_quantizer_from_env()
        print(f"ğŸ”§ Quantization Mode: {self.get_current_config()}")
    
    def _create_quantizer_from_env(self):
        """æ ¹æ“šç’°å¢ƒè®Šæ•¸å‰µå»ºé‡åŒ–å™¨"""
        
        # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
        quant_type = os.getenv('SANERF_QUANTIZATION_TYPE', 'FP32')
        int_bits = os.getenv('SANERF_QUANTIZATION_INT_BITS')
        frac_bits = os.getenv('SANERF_QUANTIZATION_FRAC_BITS')
        
        if quant_type == 'FP32':
            # å°ç…§çµ„ï¼šä¸é‡åŒ–
            return QuantizationPlugin(enabled=False)
        
        elif quant_type == 'FP16':
            # FP16æ¨¡å¼
            return QuantizationPlugin("FP16", enabled=True)
        
        elif quant_type.startswith('Q') and int_bits and frac_bits:
            # å›ºå®šé»é‡åŒ–æ¨¡å¼
            return QuantizationPlugin(
                precision_type=quant_type,
                int_bits=int(int_bits),
                frac_bits=int(frac_bits),
                enabled=True
            )
        
        else:
            print(f"âš ï¸  Unknown quantization config, falling back to FP32")
            return QuantizationPlugin(enabled=False)
    
    def get_current_config(self):
        """ç²å–ç•¶å‰é‡åŒ–é…ç½®è³‡è¨Š"""
        quant_type = os.getenv('SANERF_QUANTIZATION_TYPE', 'FP32')
        if quant_type == 'FP32':
            return "FP32 (Baseline - No Quantization)"
        elif quant_type == 'FP16':
            return "FP16 (Half Precision)"
        else:
            int_bits = os.getenv('SANERF_QUANTIZATION_INT_BITS', 'N/A')
            frac_bits = os.getenv('SANERF_QUANTIZATION_FRAC_BITS', 'N/A')
            return f"{quant_type} (Int: {int_bits}, Frac: {frac_bits})"
    
    def quantize(self, tensor):
        """é‡åŒ–å¼µé‡"""
        return self.quantizer(tensor)
    
    def __call__(self, tensor):
        """ä½¿å°è±¡å¯èª¿ç”¨"""
        return self.quantize(tensor)

# å…¨åŸŸé‡åŒ–ç®¡ç†å™¨å¯¦ä¾‹
_global_quant_manager = None

def get_quantization_manager():
    """ç²å–å…¨åŸŸé‡åŒ–ç®¡ç†å™¨"""
    global _global_quant_manager
    if _global_quant_manager is None:
        _global_quant_manager = DynamicQuantizationManager()
    return _global_quant_manager

def quantize_tensor(tensor):
    """ä¾¿æ·çš„å¼µé‡é‡åŒ–å‡½æ•¸"""
    return get_quantization_manager()(tensor)
